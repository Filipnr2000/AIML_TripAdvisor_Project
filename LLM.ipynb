{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file the project is using the llama-3-405b-instruct model to predict sentiment from Trip Advisor reviews\n",
    "\n",
    "Note that most of the code in this file is inspired by the LLM guide in MA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from decouple import config\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from sklearn.metrics import classification_report \n",
    "from tqdm import tqdm\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rooms are fine. service tries hard but does no...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best place to stay in nyc. want to go back mis...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's a great place. i'll always check to see i...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this hotel has some of the biggest rooms in ma...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you want to stay on the upper west side thi...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating_overall\n",
       "0  rooms are fine. service tries hard but does no...             3.0\n",
       "1  best place to stay in nyc. want to go back mis...             5.0\n",
       "2  it's a great place. i'll always check to see i...             5.0\n",
       "3  this hotel has some of the biggest rooms in ma...             5.0\n",
       "4  if you want to stay on the upper west side thi...             4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify CSV path\n",
    "csv_path = '../Preprocessing/data_preprocessed_general.csv'\n",
    "\n",
    "#creating a df from the file\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_overall\n",
       "Negative     3263\n",
       "Neutral      3982\n",
       "Positive    38291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating_overall'] = data['rating_overall'].replace(range(0, 3), 'Negative')\n",
    "data['rating_overall'] = data['rating_overall'].replace(3, 'Neutral')\n",
    "data['rating_overall'] = data['rating_overall'].replace(range(4, 6), 'Positive')\n",
    "\n",
    "result = data.groupby('rating_overall').size()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2277, 2)\n",
      "                                                    text rating_overall\n",
      "10586  great location for what we were seeing in ny, ...       Positive\n",
      "28420  the hotel staff are very good. friendly, accom...       Positive\n",
      "30457  clean and comfortable hotel - staff very helpf...       Positive\n",
      "43765  hotel was sound. was in town for pistons and i...       Positive\n",
      "14475  great location on the magnificent mile. beauti...       Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fraction = 0.05  \n",
    "df_sample = data.sample(frac=fraction, random_state=42)\n",
    "\n",
    "# Display the shape of the sampled DataFrame\n",
    "print(df_sample.shape)\n",
    "\n",
    "# Display the first few rows of the sampled DataFrame\n",
    "print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (455, 2)\n",
      "Test DataFrame shape: (1822, 2)\n",
      "Train DataFrame:\n",
      "                                                    text rating_overall\n",
      "42449  my stay at the baymont was more than i expecte...       Positive\n",
      "10955  great location near irish bars and flying sauc...       Positive\n",
      "6233   i stay here at least once a month for a due du...       Positive\n",
      "37721  excellent. comfortable and friendly.\\nstaff wa...       Positive\n",
      "39127  nice, clean, upscale but expensive. i was look...       Positive\n",
      "\n",
      "Test DataFrame:\n",
      "                                                    text rating_overall\n",
      "1655   everthing was superb and our room was exceptio...       Positive\n",
      "44129  very cosy location, but not quite up to standa...       Positive\n",
      "13254  fabulous location, great rooms and they know i...       Positive\n",
      "19543  this was the best staff i have experienced @ a...       Positive\n",
      "39045  i just liked the location other than that, ver...       Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split df_sample into train (80%) and test (20%) sets\n",
    "train_df, test_df = train_test_split(df_sample, test_size=0.8, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting DataFrames\n",
    "print(\"Train DataFrame shape:\", train_df.shape)\n",
    "print(\"Test DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Train DataFrame:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_overall\n",
       "Negative     46\n",
       "Neutral      38\n",
       "Positive    371\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test = train_df.groupby('rating_overall').size()\n",
    "\n",
    "result_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to WatsonX and checking the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = config(\"WX_API_KEY\")\n",
    "WX_PROJECT_ID = config(\"WX_PROJECT_ID\")\n",
    "WX_API_URL = 'https://us-south.ml.cloud.ibm.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "credentials = Credentials(\n",
    "    url = WX_API_URL,\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=WX_PROJECT_ID\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"meta-llama/llama-3-405b-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'meta-llama/llama-3-405b-instruct',\n",
       " 'model_version': '3.1.0',\n",
       " 'created_at': '2025-05-07T12:45:57.971Z',\n",
       " 'results': [{'generated_text': \" Here's a step-by-step guide to making a delicious homemade pizza:\\nIngredients:\\n\\n* 1 \",\n",
       "   'generated_token_count': 20,\n",
       "   'input_token_count': 8,\n",
       "   'stop_reason': 'max_tokens'}],\n",
       " 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.',\n",
       "    'id': 'disclaimer_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'},\n",
       "   {'message': \"The value of 'parameters.max_new_tokens' for this model was set to value 20\",\n",
       "    'id': 'unspecified_max_new_tokens',\n",
       "    'additional_properties': {'limit': 0,\n",
       "     'new_value': 20,\n",
       "     'parameter': 'parameters.max_new_tokens',\n",
       "     'value': 0}}]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How do I make a pizza?\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "generated_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0.2,              # Higher temperature means more randomness - In this case we don't want randomness\n",
    "    max_new_tokens=20,\n",
    "    top_p=0.7,        \n",
    "    stop_sequences=[\".\", \"\\n\"], # Stop generating text when these sequences are encountered\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"meta-llama/llama-3-405b-instruct\", \n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using zero shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = \"\"\"You task is to classify the sentiment of hotel reviews from Trip Advisor provided in the text into one of three sentiment categories.\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct sentiment category to the review. Your answer should only inlcude the correct sentiment category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [03:03<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a string with all categories\n",
    "CATEGORIES = \"- \" + \"\\n- \".join(train_df[\"rating_overall\"].unique())\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(train_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = zero_shot.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.91      0.86        46\n",
      "     Neutral       0.46      0.45      0.45        38\n",
      "    Positive       0.96      0.95      0.96       371\n",
      "\n",
      "    accuracy                           0.91       455\n",
      "   macro avg       0.74      0.77      0.76       455\n",
      "weighted avg       0.91      0.91      0.91       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_df.rating_overall, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using few shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot = \"\"\"You task is to classify the sentiment of hotel reviews from Trip Advisor provided in the text into one of three sentiment categories. You are given some review examples.\n",
    "\n",
    "EXAMPLES:\n",
    "- Text: \"the hotel was great and the staff were friendly and helpful.\"\n",
    "  Sentiment category: Positive\n",
    "- Text: \"the service was amazing and the food was delicious.\"\n",
    "  Sentiment category: Positive\n",
    "- Text: \"the room was dirty and the service was terrible, bad value.\"\n",
    "  Sentiment category: Negative\n",
    "- Text: \"the location was perfect, but the staff were rude.\"\n",
    "  Sentiment category: Negative\n",
    "- Text: \"the location was pretty good, but the amenities were lacking.\"\n",
    "  Sentiment category: Neutral\n",
    "- Text: \"the hotel was average, breakfast was good but the rooms were a bit dirty.\"\n",
    "  Sentiment category: Neutral\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct sentiment category to the review. Your answer should only inlcude the correct sentiment category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [02:56<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "fs_predictions_test = []\n",
    "\n",
    "for text in tqdm(train_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    fs_prompt = few_shot.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    fs_response = model.generate(fs_prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    fs_prediction = fs_response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    fs_predictions_test.append(fs_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "    Negative       0.86      0.80      0.83        46\n",
      "     Neutral       0.33      0.63      0.44        38\n",
      "    Positive       0.98      0.89      0.93       371\n",
      "\n",
      "    accuracy                           0.86       455\n",
      "   macro avg       0.54      0.58      0.55       455\n",
      "weighted avg       0.91      0.86      0.88       455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_df.rating_overall, fs_predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CoT Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoT = \"\"\"Your task is to classify the sentiment of hotel reviews from Trip Advisor into one of three categories. Think step by step.\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Assign the correct sentiment category to the review. Your answer should only inlcude the correct sentiment category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [02:45<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "CoT_predictions_test = []\n",
    "\n",
    "for text in tqdm(train_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    CoT_prompt = CoT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    CoT_response = model.generate(CoT_prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    CoT_prediction = CoT_response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    CoT_predictions_test.append(CoT_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.89      0.84        46\n",
      "     Neutral       0.50      0.42      0.46        38\n",
      "    Positive       0.96      0.96      0.96       371\n",
      "\n",
      "    accuracy                           0.91       455\n",
      "   macro avg       0.75      0.76      0.75       455\n",
      "weighted avg       0.91      0.91      0.91       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_df.rating_overall, CoT_predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the best model on the remaining test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1822/1822 [10:48<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a string with all categories\n",
    "CATEGORIES = \"- \" + \"\\n- \".join(test_df[\"rating_overall\"].unique())\n",
    "\n",
    "Final_CoT_predictions_test = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    Final_CoT_prompt = CoT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    Final_CoT_response = model.generate(Final_CoT_prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    Final_CoT_prediction = Final_CoT_response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    Final_CoT_predictions_test.append(Final_CoT_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.72      0.90      0.80       111\n",
      "     Neutral       0.53      0.48      0.51       180\n",
      "    Positive       0.96      0.95      0.96      1531\n",
      "\n",
      "    accuracy                           0.90      1822\n",
      "   macro avg       0.74      0.78      0.75      1822\n",
      "weighted avg       0.90      0.90      0.90      1822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df.rating_overall, Final_CoT_predictions_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
